{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86da100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask in c:\\users\\paula\\anaconda3\\envs\\pmb-072125\\lib\\site-packages (2025.7.0)\n",
      "Requirement already satisfied: click>=8.1 in c:\\users\\paula\\anaconda3\\envs\\pmb-072125\\lib\\site-packages (from dask) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in c:\\users\\paula\\anaconda3\\envs\\pmb-072125\\lib\\site-packages (from dask) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\paula\\anaconda3\\envs\\pmb-072125\\lib\\site-packages (from dask) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\paula\\anaconda3\\envs\\pmb-072125\\lib\\site-packages (from dask) (25.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in c:\\users\\paula\\anaconda3\\envs\\pmb-072125\\lib\\site-packages (from dask) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\paula\\anaconda3\\envs\\pmb-072125\\lib\\site-packages (from dask) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\paula\\anaconda3\\envs\\pmb-072125\\lib\\site-packages (from dask) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\paula\\anaconda3\\envs\\pmb-072125\\lib\\site-packages (from click>=8.1->dask) (0.4.6)\n",
      "Requirement already satisfied: locket in c:\\users\\paula\\anaconda3\\envs\\pmb-072125\\lib\\site-packages (from partd>=1.4.0->dask) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70659c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/26.2 MB 7.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.6/26.2 MB 19.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.5/26.2 MB 38.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.2 MB 40.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.2 MB 40.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 22.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-21.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7711a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7059fe68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fecha_dato               string[pyarrow]\n",
       "ncodpers                         float64\n",
       "ind_empleado             string[pyarrow]\n",
       "pais_residencia          string[pyarrow]\n",
       "sexo                     string[pyarrow]\n",
       "age                              float64\n",
       "fecha_alta               string[pyarrow]\n",
       "ind_nuevo                        float64\n",
       "antiguedad                       float64\n",
       "indrel                           float64\n",
       "ult_fec_cli_1t                   float64\n",
       "indrel_1mes                      float64\n",
       "tiprel_1mes              string[pyarrow]\n",
       "indresi                  string[pyarrow]\n",
       "indext                   string[pyarrow]\n",
       "conyuemp                         float64\n",
       "canal_entrada            string[pyarrow]\n",
       "indfall                  string[pyarrow]\n",
       "tipodom                          float64\n",
       "cod_prov                         float64\n",
       "nomprov                  string[pyarrow]\n",
       "ind_actividad_cliente            float64\n",
       "renta                            float64\n",
       "segmento                 string[pyarrow]\n",
       "ind_ahor_fin_ult1                float64\n",
       "ind_aval_fin_ult1                float64\n",
       "ind_cco_fin_ult1                 float64\n",
       "ind_cder_fin_ult1                float64\n",
       "ind_cno_fin_ult1                 float64\n",
       "ind_ctju_fin_ult1                float64\n",
       "ind_ctma_fin_ult1                float64\n",
       "ind_ctop_fin_ult1                float64\n",
       "ind_ctpp_fin_ult1                float64\n",
       "ind_deco_fin_ult1                float64\n",
       "ind_deme_fin_ult1                float64\n",
       "ind_dela_fin_ult1                float64\n",
       "ind_ecue_fin_ult1                float64\n",
       "ind_fond_fin_ult1                float64\n",
       "ind_hip_fin_ult1                 float64\n",
       "ind_plan_fin_ult1                float64\n",
       "ind_pres_fin_ult1                float64\n",
       "ind_reca_fin_ult1                float64\n",
       "ind_tjcr_fin_ult1                float64\n",
       "ind_valo_fin_ult1                float64\n",
       "ind_viv_fin_ult1                 float64\n",
       "ind_nomina_ult1                  float64\n",
       "ind_nom_pens_ult1                float64\n",
       "ind_recibo_ult1                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.read_csv(\"Train.csv\", sep=\",\", assume_missing=True, sample=100000).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5f422f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dd.read_csv(\"Train.csv\", sep=\",\", assume_missing=True, sample=100000)\n",
    "df2 = dd.read_csv(\"Test.csv\", sep=\",\", assume_missing=True, sample=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12dd2273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45009a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"fecha_dato\",\"ncodpers\",\"ind_empleado\",\"pais_residencia\",\"sexo\",\"age\",\"fecha_alta\",\"ind_nuevo\",\"antiguedad\",\"indrel\",\"ult_fec_cli_1t\",\"indrel_1mes\",\"tiprel_1mes\",\"indresi\",\"indext\",\"conyuemp\",\"canal_entrada\",\"indfall\",\"tipodom\",\"cod_prov\",\"nomprov\",\"ind_actividad_cliente\",\"renta\",\"segmento\",\"ind_ahor_fin_ult1\",\"ind_aval_fin_ult1\",\"ind_cco_fin_ult1\",\"ind_cder_fin_ult1\",\"ind_cno_fin_ult1\",\"ind_ctju_fin_ult1\",\"ind_ctma_fin_ult1\",\"ind_ctop_fin_ult1\",\"ind_ctpp_fin_ult1\",\"ind_deco_fin_ult1\",\"ind_deme_fin_ult1\",\"ind_dela_fin_ult1\",\"ind_ecue_fin_ult1\",\"ind_fond_fin_ult1\",\"ind_hip_fin_ult1\",\"ind_plan_fin_ult1\",\"ind_pres_fin_ult1\",\"ind_reca_fin_ult1\",\"ind_tjcr_fin_ult1\",\"ind_valo_fin_ult1\",\"ind_viv_fin_ult1\",\"ind_nomina_ult1\",\"ind_nom_pens_ult1\",\"ind_recibo_ult1\"\n",
      "\n",
      "2015-01-28,1375586,N,ES,H, 35,2015-01-12, 0,      6, 1,,1.0,A,S,N,,KHL,N, 1,29,\"MALAGA\", 1,87218.1,02 - PARTICULARES,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0, 0,0\n",
      "\n",
      "2015-01-28,1050611,N,ES,V, 23,2012-08-10, 0,     35, 1,,1,I,S,S,,KHE,N, 1,13,\"CIUDAD REAL\", 0,35548.74,03 - UNIVERSITARIO,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0, 0,0\n",
      "\n",
      "2015-01-28,1050612,N,ES,V, 23,2012-08-10, 0,     35, 1,,1,I,S,N,,KHE,N, 1,13,\"CIUDAD REAL\", 0,122179.11000000002,03 - UNIVERSITARIO,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0, 0,0\n",
      "\n",
      "2015-01-28,1050613,N,ES,H, 22,2012-08-10, 0,     35, 1,,1,I,S,N,,KHD,N, 1,50,\"ZARAGOZA\", 0,119775.54,03 - UNIVERSITARIO,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0, 0, 0,0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"Train.csv\", 'r') as f:\n",
    "    for _ in range(5):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc0aef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fecha_dato               string[pyarrow]\n",
      "ncodpers                         float64\n",
      "ind_empleado             string[pyarrow]\n",
      "pais_residencia          string[pyarrow]\n",
      "sexo                     string[pyarrow]\n",
      "age                              float64\n",
      "fecha_alta               string[pyarrow]\n",
      "ind_nuevo                        float64\n",
      "antiguedad                       float64\n",
      "indrel                           float64\n",
      "ult_fec_cli_1t                   float64\n",
      "indrel_1mes                      float64\n",
      "tiprel_1mes              string[pyarrow]\n",
      "indresi                  string[pyarrow]\n",
      "indext                   string[pyarrow]\n",
      "conyuemp                         float64\n",
      "canal_entrada            string[pyarrow]\n",
      "indfall                  string[pyarrow]\n",
      "tipodom                          float64\n",
      "cod_prov                         float64\n",
      "nomprov                  string[pyarrow]\n",
      "ind_actividad_cliente            float64\n",
      "renta                            float64\n",
      "segmento                 string[pyarrow]\n",
      "ind_ahor_fin_ult1                float64\n",
      "ind_aval_fin_ult1                float64\n",
      "ind_cco_fin_ult1                 float64\n",
      "ind_cder_fin_ult1                float64\n",
      "ind_cno_fin_ult1                 float64\n",
      "ind_ctju_fin_ult1                float64\n",
      "ind_ctma_fin_ult1                float64\n",
      "ind_ctop_fin_ult1                float64\n",
      "ind_ctpp_fin_ult1                float64\n",
      "ind_deco_fin_ult1                float64\n",
      "ind_deme_fin_ult1                float64\n",
      "ind_dela_fin_ult1                float64\n",
      "ind_ecue_fin_ult1                float64\n",
      "ind_fond_fin_ult1                float64\n",
      "ind_hip_fin_ult1                 float64\n",
      "ind_plan_fin_ult1                float64\n",
      "ind_pres_fin_ult1                float64\n",
      "ind_reca_fin_ult1                float64\n",
      "ind_tjcr_fin_ult1                float64\n",
      "ind_valo_fin_ult1                float64\n",
      "ind_viv_fin_ult1                 float64\n",
      "ind_nomina_ult1                  float64\n",
      "ind_nom_pens_ult1                float64\n",
      "ind_recibo_ult1                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df1.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d368c9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1deb6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fecha_dato               string[pyarrow]\n",
      "ncodpers                         float64\n",
      "ind_empleado             string[pyarrow]\n",
      "pais_residencia          string[pyarrow]\n",
      "sexo                     string[pyarrow]\n",
      "age                              float64\n",
      "fecha_alta               string[pyarrow]\n",
      "ind_nuevo                        float64\n",
      "antiguedad                       float64\n",
      "indrel                           float64\n",
      "ult_fec_cli_1t                   float64\n",
      "indrel_1mes                      float64\n",
      "tiprel_1mes              string[pyarrow]\n",
      "indresi                  string[pyarrow]\n",
      "indext                   string[pyarrow]\n",
      "conyuemp                 string[pyarrow]\n",
      "canal_entrada            string[pyarrow]\n",
      "indfall                  string[pyarrow]\n",
      "tipodom                          float64\n",
      "cod_prov                         float64\n",
      "nomprov                  string[pyarrow]\n",
      "ind_actividad_cliente            float64\n",
      "renta                    string[pyarrow]\n",
      "segmento                 string[pyarrow]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7846b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'fecha_dato':         'string[pyarrow]',\n",
    "    'ncodpers':           'float64',\n",
    "    'ind_empleado':       'string[pyarrow]',\n",
    "    'pais_residencia':    'string[pyarrow]',\n",
    "    'sexo':               'string[pyarrow]',\n",
    "    'age':                 'float64',\n",
    "    'fecha_alta':          'string[pyarrow]',\n",
    "    'ind_nuevo':           'float64',\n",
    "    'antiguedad':          'float64',\n",
    "    'indrel':              'float64',\n",
    "    'ult_fec_cli_1t':      'float64',\n",
    "    'indrel_1mes':         'float64',\n",
    "    'tiprel_1mes':         'string[pyarrow]',\n",
    "    'indresi':             'string[pyarrow]',\n",
    "    'indext':              'string[pyarrow]',\n",
    "    'conyuemp':            'float64',\n",
    "    'canal_entrada':       'string[pyarrow]',\n",
    "    'indfall':             'string[pyarrow]',\n",
    "    'tipodom':             'float64',\n",
    "    'cod_prov':            'float64',\n",
    "    'nomprov':             'string[pyarrow]',\n",
    "    'ind_actividad_cliente': 'float64',\n",
    "    'renta':                'float64',\n",
    "    'segmento':             'string[pyarrow]',\n",
    "    'ind_ahor_fin_ult1':    'float64',\n",
    "    'ind_aval_fin_ult1':    'float64',\n",
    "    'ind_cco_fin_ult1':     'float64',\n",
    "    'ind_cder_fin_ult1':    'float64',\n",
    "    'ind_cno_fin_ult1':     'float64',\n",
    "    'ind_ctju_fin_ult1':    'float64',\n",
    "    'ind_ctma_fin_ult1':    'float64',\n",
    "    'ind_ctop_fin_ult1':    'float64',\n",
    "    'ind_ctpp_fin_ult1':    'float64',\n",
    "    'ind_deco_fin_ult1':    'float64',\n",
    "    'ind_deme_fin_ult1':    'float64',\n",
    "    'ind_dela_fin_ult1':    'float64',\n",
    "    'ind_ecue_fin_ult1':    'float64',\n",
    "    'ind_fond_fin_ult1':    'float64',\n",
    "    'ind_hip_fin_ult1':     'float64',\n",
    "    'ind_plan_fin_ult1':    'float64',\n",
    "    'ind_pres_fin_ult1':    'float64',\n",
    "    'ind_reca_fin_ult1':    'float64',\n",
    "    'ind_tjcr_fin_ult1':    'float64',\n",
    "    'ind_valo_fin_ult1':    'float64',\n",
    "    'ind_viv_fin_ult1':     'float64',\n",
    "    'ind_nomina_ult1':      'float64',\n",
    "    'ind_nom_pens_ult1':    'float64',\n",
    "    'ind_recibo_ult1':      'float64'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02281c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dd.read_csv(\"Train.csv\", sep=\",\", assume_missing=True, dtype = dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "962e6372",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2016-01-15'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:1161\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_tokens\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: Cannot cast array data from dtype('O') to dtype('float64') according to the rule 'safe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m num_col = \u001b[38;5;28mlen\u001b[39m(df1.columns)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m num_row = \u001b[43mdf1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_row\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paula\\anaconda3\\envs\\pmb-072125\\Lib\\site-packages\\dask\\base.py:373\u001b[39m, in \u001b[36mDaskMethodsMixin.compute\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m    350\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[32m    351\u001b[39m \n\u001b[32m    352\u001b[39m \u001b[33;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m \u001b[33;03m    dask.compute\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     (result,) = \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paula\\anaconda3\\envs\\pmb-072125\\Lib\\site-packages\\dask\\base.py:681\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     expr = expr.optimize()\n\u001b[32m    679\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(flatten(expr.__dask_keys__()))\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paula\\anaconda3\\envs\\pmb-072125\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:351\u001b[39m, in \u001b[36m_read_csv\u001b[39m\u001b[34m(block, part, columns, reader, header, dtypes, head, colname, full_columns, enforce, kwargs, blocksize)\u001b[39m\n\u001b[32m    348\u001b[39m         rest_kwargs[\u001b[33m\"\u001b[39m\u001b[33musecols\u001b[39m\u001b[33m\"\u001b[39m] = _columns\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# Call `pandas_read_text`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m df = \u001b[43mpandas_read_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrest_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrite_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43menforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m project_after_read:\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df[columns]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paula\\anaconda3\\envs\\pmb-072125\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:77\u001b[39m, in \u001b[36mpandas_read_text\u001b[39m\u001b[34m(reader, b, header, kwargs, dtypes, columns, write_header, enforce, path)\u001b[39m\n\u001b[32m     75\u001b[39m bio.write(b)\n\u001b[32m     76\u001b[39m bio.seek(\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m df = \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtypes:\n\u001b[32m     79\u001b[39m     coerce_dtypes(df, dtypes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paula\\anaconda3\\envs\\pmb-072125\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paula\\anaconda3\\envs\\pmb-072125\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paula\\anaconda3\\envs\\pmb-072125\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paula\\anaconda3\\envs\\pmb-072125\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:921\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:1066\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_column_data\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:1167\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_tokens\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '2016-01-15'"
     ]
    }
   ],
   "source": [
    "num_col = len(df1.columns)\n",
    "num_row = df1.shape[0].compute()\n",
    "print(f\"Rows: {num_row}, Columns: {num_col}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmb-072125",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
